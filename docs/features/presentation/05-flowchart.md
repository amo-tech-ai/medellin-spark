# Presentation-AI System Flow

## Accurate System Flowchart

```mermaid
flowchart LR
    Start([User Opens App]) --> Dashboard[Dashboard Page]

    subgraph Input["üìù User Input"]
        Dashboard --> Prompt[Enter Topic in Textarea]
        Prompt --> Settings[Configure Settings]
        Settings --> |"‚Ä¢ Slides: 5-20<br/>‚Ä¢ Language<br/>‚Ä¢ Style<br/>‚Ä¢ Model<br/>‚Ä¢ Theme<br/>‚Ä¢ Web Search Toggle"| Generate[Click Generate]
    end

    subgraph StateManagement["üîÑ State (Zustand)"]
        Generate --> State[Update Global State]
        State --> |"presentationInput<br/>numSlides<br/>language<br/>webSearchEnabled<br/>modelProvider"| Navigate
    end

    subgraph Navigation["üß≠ Routing"]
        Navigate --> CreateDoc[Create BaseDocument]
        CreateDoc --> Redirect["/presentation/generate/[id]"]
    end

    subgraph OutlineGen["ü§ñ Outline Generation"]
        Redirect --> CheckSearch{Web Search<br/>Enabled?}
        CheckSearch -->|Yes| OutlineSearch["/api/outline-with-search"]
        CheckSearch -->|No| OutlineSimple["/api/outline"]

        OutlineSearch --> Tool[Tavily Search Tool]
        Tool --> GPT1[OpenAI GPT-4<br/>with Tools]

        OutlineSimple --> GPT2[OpenAI GPT-4]

        GPT1 --> StreamTitle[Stream: Title]
        GPT2 --> StreamTitle
        StreamTitle --> StreamOutline[Stream: Outline Topics]
    end

    subgraph SlideGen["‚ú® Slide Generation"]
        StreamOutline --> GenAPI["/api/presentation/generate"]
        GenAPI --> GPT3[OpenAI GPT-4]
        GPT3 --> StreamXML[Stream XML Slides]
        StreamXML --> Parse[Parse to JSON]
        Parse --> CreateSlides[Create Slide Objects]
    end

    subgraph Database["üíæ Database"]
        CreateSlides --> SaveDB[(Prisma Save)]
        SaveDB --> Tables[Update Tables:<br/>Presentation<br/>BaseDocument]
    end

    subgraph Render["üé® Rendering"]
        CreateSlides --> PlateEditor[Plate Editor Init]
        PlateEditor --> MapSlides[Map JSON to Components]
        MapSlides --> Layouts[Render Layout:<br/>TEXT, BULLETS, CHART,<br/>TABLE, TIMELINE, etc.]

        Layouts --> CheckImages{Has Image<br/>Queries?}
        CheckImages -->|Yes| ImgGen[Generate Images]
        CheckImages -->|No| Display

        ImgGen --> ImgAPI[Together AI /<br/>Unsplash API]
        ImgAPI --> Display[Display Presentation]
    end

    subgraph UserActions["üë§ User Actions"]
        Display --> Edit{User Action?}
        Edit -->|Edit| PlateEdit[Plate Editor]
        Edit -->|Present| PresentMode[Fullscreen Present]
        Edit -->|Export| ExportMenu[Export Menu]

        PlateEdit --> DragDrop[Drag & Drop Slides]
        PlateEdit --> RichText[Rich Text Editing]
        PlateEdit --> AutoSave[Auto-save to DB]

        ExportMenu --> PDF[Generate PDF]
        ExportMenu --> PPTX[Generate PPTX]
    end

    AutoSave --> Tables
    PDF --> Download1[üì• Download]
    PPTX --> Download2[üì• Download]

    style Start fill:#e1f5ff
    style Dashboard fill:#fff4e1
    style GPT1 fill:#ffebee
    style GPT2 fill:#ffebee
    style GPT3 fill:#ffebee
    style SaveDB fill:#e8f5e9
    style Display fill:#f3e5f5
    style Download1 fill:#c8e6c9
    style Download2 fill:#c8e6c9
```

---

## How The System Actually Works

### Real Data Flow (Based on Code Analysis)

**Presentation-AI** transforms ANY topic into professional slides. Here's the actual system flow from the codebase at `/home/sk/medellin-spark/reference-presentation-ai`:

---

### Phase 1: User Input ‚Üí State Management

**What Happens:**
1. User lands on `/presentation` dashboard
2. Types ANY topic in textarea (e.g., "AI startup pitch", "ML model architecture", "Company Q4 results")
3. Configures via UI:
   - **Slides**: 5-20 count
   - **Language**: EN, ES, FR, DE, etc. (12 languages)
   - **Style**: Professional / Casual
   - **AI Model**: OpenAI GPT-4 / Ollama / LM Studio
   - **Theme**: 9 built-in or custom
   - **Web Search**: Toggle on/off
4. Clicks "Generate" or presses `Ctrl+Enter`

**State Updates (Zustand):**
```typescript
{
  presentationInput: "user topic",
  numSlides: 10,
  language: "en-US",
  presentationStyle: "professional",
  webSearchEnabled: true,
  modelProvider: "openai",
  theme: "default"
}
```

---

### Phase 2: Navigation ‚Üí Document Creation

**What Happens:**
1. System creates `BaseDocument` record in database
2. Navigates to `/presentation/generate/[id]`
3. Generation page initializes with presentation ID
4. Sets generation flags in state:
   ```typescript
   {
     isGeneratingOutline: true,
     shouldStartOutlineGeneration: true
   }
   ```

---

### Phase 3: Outline Generation (Two Paths)

**Path A: Web Search Enabled** ‚Üí `/api/presentation/outline-with-search`
```typescript
POST /api/presentation/outline-with-search
{
  prompt: "AI startup pitch",
  numberOfCards: 10,
  language: "en-US",
  modelProvider: "openai"
}
```

**AI Process:**
1. OpenAI GPT-4 receives system prompt with Tavily search tool
2. AI decides which web searches to run (2-5 queries max)
3. Example searches: "AI startup funding trends 2025", "pitch deck best practices"
4. AI uses search results to enrich outline
5. Streams response:
   ```xml
   <TITLE>AI Startup: Investor Pitch Deck</TITLE>

   # Problem Statement
   - Current market pain points
   - Validated customer needs
   - Opportunity size
   ```

**Path B: No Web Search** ‚Üí `/api/presentation/outline`
- Same flow but AI generates outline from knowledge only
- Faster (~3-5 seconds vs 8-10 seconds)

**Output:**
- Title string
- Array of outline topics (5-20 items, each with 2-3 bullets)
- Optional: Search results JSON

---

### Phase 4: Slide Content Generation

**What Happens:**
```typescript
POST /api/presentation/generate
{
  title: "AI Startup: Investor Pitch Deck",
  prompt: "AI startup pitch",
  outline: ["# Problem...", "# Solution...", ...],
  language: "en-US",
  tone: "professional",
  searchResults: [...],  // if web search was used
  modelProvider: "openai"
}
```

**AI Process:**
1. OpenAI GPT-4 receives massive prompt template with:
   - Title and outline
   - Search context (if available)
   - 15+ layout options (TEXT, BULLETS, CHART, TABLE, etc.)
   - Image query requirements
   - XML format specification

2. AI generates **streaming XML** response:
   ```xml
   <PRESENTATION>
     <SECTION layout="vertical">
       <H1>Problem Statement</H1>
       <TEXT>Current market challenges...</TEXT>
       <IMG>professional business meeting discussing challenges, modern office, diverse team</IMG>
     </SECTION>

     <SECTION layout="left">
       <H2>Market Opportunity</H2>
       <BULLETS>
         <LI>$50B TAM by 2025</LI>
         <LI>30% YoY growth</LI>
       </BULLETS>
       <IMG>upward trending business graph, financial growth visualization</IMG>
     </SECTION>

     <SECTION layout="right">
       <H2>Our Solution</H2>
       <CHART charttype="bar">
         <DATA><LABEL>Q1</LABEL><VALUE>100</VALUE></DATA>
         <DATA><LABEL>Q2</LABEL><VALUE>250</VALUE></DATA>
       </CHART>
     </SECTION>
   </PRESENTATION>
   ```

3. Frontend receives **streaming chunks**
4. Parser (`utils/parser.ts`) converts XML ‚Üí JSON structure:
   ```typescript
   {
     slides: [
       {
         id: "slide-1",
         layout: "vertical",
         content: [/* Plate Editor nodes */],
         imageQuery: "professional business meeting..."
       },
       // ...
     ]
   }
   ```

---

### Phase 5: Database Persistence

**What Gets Saved:**
```typescript
// BaseDocument table
{
  id: "clx123...",
  title: "AI Startup: Investor Pitch Deck",
  type: "PRESENTATION",
  userId: "user-id",
  thumbnailUrl: null,
  isPublic: false
}

// Presentation table
{
  id: "clx123...",  // same as BaseDocument.id
  content: {/* Full JSON slides */},
  theme: "default",
  imageSource: "ai",
  prompt: "AI startup pitch",
  presentationStyle: "professional",
  language: "en-US",
  outline: ["# Problem...", "# Solution...", ...],
  searchResults: {/* Tavily results */}
}
```

---

### Phase 6: Rendering with Plate Editor

**What Happens:**
1. **Plate Editor Initialization:**
   - Loads 40+ custom plugins
   - Registers 15+ layout components
   - Sets up drag-and-drop
   - Configures auto-save

2. **Slide Rendering:**
   Each slide JSON ‚Üí React components:
   ```typescript
   // JSON
   { type: "BULLETS", children: [
     { type: "LI", text: "Point 1" },
     { type: "LI", text: "Point 2" }
   ]}

   // Renders to
   <BulletElement>
     <BulletItem icon="check">Point 1</BulletItem>
     <BulletItem icon="check">Point 2</BulletItem>
   </BulletElement>
   ```

3. **Layout Types (15+):**
   - **TEXT**: Paragraphs with headings
   - **BULLETS**: Icon lists
   - **TIMELINE**: Chronological events
   - **STEP-BY-STEP**: Process flows
   - **COMPARISON**: Side-by-side
   - **BEFORE-AFTER**: Transformation
   - **PROS-CONS**: Advantages/disadvantages
   - **TABLE**: Data tables
   - **CHART**: Bar, Pie, Line, Scatter, Radar, Area
   - **ICON-LIST**: Icon-based lists
   - **STAIRCASE**: Progressive steps
   - **PYRAMID**: Hierarchical
   - **CYCLE**: Circular processes
   - **BOX**: Boxed content
   - **CALLOUT**: Highlighted quotes

4. **Image Generation (Async):**
   ```typescript
   if (slide.imageQuery) {
     // Option A: Together AI
     POST https://api.together.xyz/v1/images/generations
     { prompt: slide.imageQuery, model: "black-forest-labs/FLUX.1-schnell" }

     // Option B: Unsplash
     GET https://api.unsplash.com/search/photos?query={imageQuery}
   }
   ```
   - Displays placeholder while loading
   - Updates slide when image ready
   - Stores in GeneratedImage table

---

### Phase 7: User Editing & Export

**Edit Mode:**
- **Plate Editor** provides:
  - Rich text formatting
  - Inline editing
  - Component-level edits (charts, tables, etc.)
- **Drag & Drop** (@dnd-kit):
  - Reorder slides
  - Move content blocks
- **Auto-save** (Zustand + Prisma):
  - Debounced updates every 2 seconds
  - Saves to `presentation.content` JSON field

**Present Mode:**
- Fullscreen view (`/presentation/[id]/present`)
- Keyboard navigation (arrows, space)
- Slide counter
- Exit to edit mode

**Export:**
- **PDF**:
  - Uses `html2canvas` + `pdf-lib`
  - Renders each slide as image ‚Üí PDF page
- **PPTX**:
  - Uses `pptxgenjs`
  - Limited support (basic layouts only)

---

## Real Example: AI Startup Pitch

**Input:**
```
Topic: "AI-powered coding assistant startup pitch"
Slides: 8
Language: English
Style: Professional
Web Search: ON
Model: OpenAI GPT-4
```

**Actual Output (Generated in 23 seconds):**

1. **Title Slide** (layout: vertical)
   - "CodeAI: Your Intelligent Coding Partner"
   - Hero image of developer with AI assistant

2. **Problem** (layout: left)
   - Bullets: Developer productivity gap, code quality issues, onboarding costs
   - Image: frustrated developer

3. **Market** (layout: right)
   - Pie chart: TAM $50B, SAM $10B, SOM $500M
   - Image: market growth graph

4. **Solution** (layout: vertical)
   - Text: AI-powered code completion, bug detection, documentation
   - Image: sleek coding interface

5. **Product Demo** (layout: left)
   - Step-by-step: Install ‚Üí Configure ‚Üí Code ‚Üí Deploy
   - Image: product screenshots

6. **Traction** (layout: right)
   - Bar chart: Users (Q1-Q4), Revenue growth
   - Image: upward trending metrics

7. **Business Model** (layout: comparison)
   - Table: Free vs Pro vs Enterprise
   - Image: pricing tiers visualization

8. **Call to Action** (layout: vertical)
   - Callout: "Join 10,000+ developers. Sign up today!"
   - Image: team celebration

**Web Search Results Used:**
- "AI coding assistant market size 2025" ‚Üí $50B TAM
- "developer productivity statistics" ‚Üí 30% time on debugging
- "code quality automation trends" ‚Üí 40% adoption growth

---

## Technical Stack (Actual Implementation)

### Frontend
- **Framework**: Next.js 15.5.4 (App Router, Turbopack)
- **UI**: React 19 + Radix UI
- **Editor**: Plate (Slate.js) - 40+ plugins
- **State**: Zustand (`presentation-state.ts`)
- **Styling**: Tailwind CSS
- **DnD**: @dnd-kit
- **Charts**: Recharts
- **Data**: TanStack Query

### Backend
- **API**: Next.js Route Handlers
- **AI**: Vercel AI SDK (`streamText`)
- **DB**: PostgreSQL + Prisma ORM
- **Auth**: NextAuth.js (Google OAuth)
- **Upload**: UploadThing

### External APIs
- **OpenAI GPT-4**: Outline + slide generation
- **Tavily**: Web search (when enabled)
- **Together AI**: Image generation (FLUX.1-schnell)
- **Unsplash**: Stock photos

### Database Schema
```
User (id, email, name, role, hasAccess)
  ‚îú‚îÄ‚îÄ Account (OAuth providers)
  ‚îú‚îÄ‚îÄ BaseDocument (id, title, type, userId)
  ‚îÇ   ‚îî‚îÄ‚îÄ Presentation (content JSON, theme, outline)
  ‚îú‚îÄ‚îÄ CustomTheme (themeData JSON)
  ‚îú‚îÄ‚îÄ FavoriteDocument
  ‚îî‚îÄ‚îÄ GeneratedImage (url, prompt)
```

---

## Key Differences from Initial Analysis

### What I Got Wrong:
1. ‚ùå Fashion example was fictional - system works for ANY topic
2. ‚ùå API flow was simplified - actual flow has two outline paths
3. ‚ùå Web search is optional with Tavily tool integration
4. ‚ùå Streaming happens at outline AND slide generation
5. ‚ùå Images generated AFTER initial render (async)

### What's Actually Correct:
1. ‚úÖ Zustand state management
2. ‚úÖ Plate editor for rendering
3. ‚úÖ XML parsing to JSON
4. ‚úÖ 15+ layout types
5. ‚úÖ Auto-save functionality
6. ‚úÖ Database structure

---

## Performance Optimizations (From Code)

### Already Implemented:
1. **Streaming Responses** - See content as it's generated
2. **Lazy Image Loading** - Placeholders first, images async
3. **Auto-save Debouncing** - Only save every 2 seconds
4. **React Query Caching** - Cached presentations list
5. **Turbopack** - Faster Next.js bundling

### Still Needed:
1. **Outline Caching** - Redis for common topics
2. **Batch Image Generation** - Parallel API calls
3. **Slide Pagination** - Load 5 slides at a time
4. **Service Worker** - Offline editing

---

## Use Cases (Any Topic!)

- ‚úÖ Startup pitch decks
- ‚úÖ Product launches
- ‚úÖ Technical architecture presentations
- ‚úÖ Sales demos
- ‚úÖ Educational lectures
- ‚úÖ Research findings
- ‚úÖ Quarterly business reviews
- ‚úÖ Marketing campaigns
- ‚úÖ Training materials
- ‚úÖ Conference talks

**NOT limited to fashion or any specific industry!**

---

## Resources

- **Repository**: `/home/sk/medellin-spark/reference-presentation-ai`
- **GitHub**: https://github.com/allweonedev/presentation-ai
- **Running**: http://localhost:3000
- **Setup Guide**: `docs/presentation/04-presentation-ai-setup.md`
- **Comparison**: `docs/presentation/03-compare.md`

---

**Updated**: 2025-10-13
**Status**: ‚úÖ Accurate system analysis based on actual codebase
**Flowchart**: Corrected to match real implementation
**Next**: Review for Medellin AI integration strategy
